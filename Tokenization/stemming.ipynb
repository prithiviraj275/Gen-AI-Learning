{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff73647",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "####  - it is the process of reducing a word to it's word stem that suffixes and prefrixes or to the roots of the words known as lemma. this is most important in Natural language understanding and Natural language processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0571873",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ed9294",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['eat','eaten','eating','history','fairly','sportly','goes','sitting','congratulations','congratulate','congratulating','congratulated','congratulatorily']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a8a6d",
   "metadata": {},
   "source": [
    "## porter stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e104aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf1cc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat  -->  eat\n",
      "eaten  -->  eaten\n",
      "eating  -->  eat\n",
      "history  -->  histori\n",
      "fairly  -->  fairli\n",
      "sportly  -->  sportli\n",
      "goes  -->  goe\n",
      "sitting  -->  sit\n",
      "congratulations  -->  congratul\n",
      "congratulate  -->  congratul\n",
      "congratulating  -->  congratul\n",
      "congratulated  -->  congratul\n",
      "congratulatorily  -->  congratulatorili\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word, \" --> \", ps.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5960c8",
   "metadata": {},
   "source": [
    "##### here we can see this root words not that much correct for all words so we try with regexpstemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc741db",
   "metadata": {},
   "source": [
    "## RegexpStemmer\n",
    "#### - it will use the regex stemmer algorithms for stemming. it is basically use regex pattern to remove the prefix and suffix values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33990b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat --> eat\n",
      "eaten --> eaten\n",
      "eating --> eat\n",
      "history --> history\n",
      "fairly --> fair\n",
      "sportly --> sport\n",
      "goes --> go\n",
      "sitting --> sitt\n",
      "congratulations --> congratulation\n",
      "congratulate --> congratulate\n",
      "congratulating --> congratulat\n",
      "congratulated --> congratulat\n",
      "congratulatorily --> congratulatori\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "reg_stem = RegexpStemmer('ing$|ed$|es$|s$|ly$', min=4)\n",
    "for word in words:\n",
    "    print(word,\"-->\",reg_stem.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70b0bc2",
   "metadata": {},
   "source": [
    "## Snowball Stemmer\n",
    "#### - it is a stemming algorithm which is also known as porter2 stemmer algorithm as it is a better version of the porter stemmer since som issues of it were fixed in this stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f05ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bbafaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat --> eat\n",
      "eaten --> eaten\n",
      "eating --> eat\n",
      "history --> histori\n",
      "fairly --> fair\n",
      "sportly --> sport\n",
      "goes --> goe\n",
      "sitting --> sit\n",
      "congratulations --> congratul\n",
      "congratulate --> congratul\n",
      "congratulating --> congratul\n",
      "congratulated --> congratul\n",
      "congratulatorily --> congratulatorili\n"
     ]
    }
   ],
   "source": [
    "snball_stem = SnowballStemmer('english')\n",
    "for word in words:\n",
    "    print(word, \"-->\", snball_stem.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6afec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAIenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
